---
title: "Explore Fire Samples"
author: "Michael Koontz"
date: "1/23/2018"
output: html_document
---

This document represents the initial exploratory data analysis of the fire samples
derived using the Earth Engine code.

```{r setup}
library(lubridate)
library(sf)
library(lme4)
library(dplyr)
library(ggplot2)
```

```{r read_files, cache = TRUE}
fires <- st_read(dsn = "../data/features/fire_perim/fire_perim_sn_16_1_shp/",
                 stringsAsFactors = FALSE)
sn <- st_read("../data/features/SierraEcoregion_Jepson/SierraEcoregion_Jepson.shp") %>% 
  st_transform(4326)
samps <- st_read("../data/fire_samples/fires-strat-samples_1-month-window_L5_none-interp.geojson")
```

What fires are available for data collection in Earth Engine?

```{r explore_fires_raw}
glimpse(fires)
fires %>% 
  filter(YEAR_ >= 1984) %>% 
  group_by(YEAR_) %>% 
  tally()

fires %>% 
  filter(YEAR_ == 2014) %>% 
  filter(FIRE_NAME == "KING")

plot(sn$geometry)
fires %>% 
  filter(YEAR_ == 2001) %>% 
  filter(FIRE_NAME == "HIGHWAY") %>% 
  filter(ALARM_DATE == "2001-07-03") %>% 
  select(geometry) %>% 
  plot(add = TRUE)

```

```{r look_at_samples}
glimpse(samps)
# Extract unique Fire ID from the sample point IDs
samps$fire_id <- substr(as.character(samps$id), start = 1, stop = 20)

plot(samps$geometry[samps$conifer_forest == 1], pch = 19)
plot(sn$geometry, add = TRUE)
```

How many fires were processed from the FRAP database (i.e. in the Sierra Nevada
and within the Landsat era)?

It looks like there are `r length(unique(samps$fire_id))` fires represented from the FRAP database with Landsat 5 imagery that can be processed.

# Variable adjustment

Some variables need to be adjusted before they can be used for modeling. Especially
circular variables. For instance, an aspect of due north is 0 degrees, but only
1 degree west of north would have an aspect of 364. These are far apart on a linear
scale, but shouldn't be.

## Topography variables

Adjust aspect to reflect "heat load index" (McCune and Keon, 2002) with southwest having a value of 1, and northeast having a value of -1

```{r adjust_aspect}
circular_aspect <- function(aspect) {
  
  new_aspect <- ((-1 * (aspect)) * pi / 180) - (3/4 * pi)
  return(cos(new_aspect))
  
}

samps$c_aspect <- circular_aspect(samps$aspect)
```


Calculate predicted potential annual direct incident radiation (also from McCune and Keon, 2002) which combines slope, aspect, and latitude

```{r calc_heat_load}
fold_aspect <- function(asp) {
  
  rad <- asp * pi / 180
  folded_aspect <- pi - abs(rad - pi)
  return(folded_aspect)
  
}

samps$folded_aspect <- fold_aspect(samps$aspect)

# G column: latitude
# H column: slope
# I column: folded aspect

# Potential 
pdir <- function(lat, slope, folded_asp) {
  lat <- lat * pi / 180
  slope <- slope * pi / 180
  exp(-1.467 + 1.582 * cos(lat) * cos(slope) - 1.5 * cos(folded_asp) * sin(slope) * sin(lat) - 0.262 * sin(lat) * sin(slope) + 0.607 * sin(folded_asp) * sin(slope))
}

samps$pdir <- pdir(samps$lat, samps$slope, samps$folded_aspect)
```

Consolidate the names of the topography variables
```{r consolidate_topo_vars}
topo_vars <- c("c_aspect", "pdir", "elev", "lat", "lon", "slope", "topo_roughness_1", "topo_roughness_2", "topo_roughness_3", "topo_roughness_4")
```

## Timing variables

Adjust ordinal day to reflect "middle of summer-ness" with August 6th (the 218th day of the year) getting a 1 and February 4th (the 35th day of the year) getting a value of -1

```{r adjust_ordinal_day}
circular_doy <- function(doy) {
  
  new_doy <- ((doy - 218) / 365) * 2 * pi
  return(cos(new_doy))
  
}

samps$c_doy <- circular_doy(samps$ordinal_day)
```


Make year an integer

```{r year_to_integer}
samps$year_ <- as.numeric(as.character(samps$year_))
```

Consolidate timing variable names.

```{r consolidate_timing_vars}
timing_vars <- c("year_", "alarm_date", "cont_date", "c_doy")
```

## Vegetation variables

Consolidate vegetation variable names.

```{r consolidate_veg_var_names}
veg_vars <- c("focal_mean_evi_1", "focal_mean_evi_2", "focal_mean_evi_3", "focal_mean_evi_4", 
              "focal_mean_ndvi_1", "focal_mean_ndvi_2", "focal_mean_ndvi_3", "focal_mean_ndvi_4",
              "focal_mean_ndwi_1", "focal_mean_ndwi_2", "focal_mean_ndwi_3", "focal_mean_ndwi_4", 
              "het_evi_1", "het_evi_2", "het_evi_3", "het_evi_4", 
              "het_ndvi_1", "het_ndvi_2", "het_ndvi_3", "het_ndvi_4",
              "het_ndwi_1", "het_ndwi_2", "het_ndwi_3", "het_ndwi_4", 
              "preFire_evi",
              "preFire_ndvi",
              "preFire_ndwi")
```

## Fire weather variables

Consolidate fire weather variable names.

```{r consolidate_fire_weather_var_names}
fireWeather_vars <- c("erc", "fm100", "tmmx")
```

# Scale all predictor variables

First consolidate all variable names.

```{r consolidate_var_names}
all_vars <- c(topo_vars, timing_vars, veg_vars, fireWeather_vars)
```

Just focus on the points from the mixed conifer/yellow pine forest

```{r conifer_subset}
mixed_con <- 
  samps %>%
  filter(conifer_forest == 1)
```

How many fires have samples from mixed conifer regions in the Sierra Nevada?
Our dataset contains `r nrow(mixed_con)` points from `r mixed_con %>% count(fire_id) %>% nrow()` fires.

Scale the predictors (ss = scaled samples)

```{r scale_samples}
ss <-
  mixed_con %>%
  mutate_at(.vars = all_vars, .funs = funs(s = as.numeric(scale(.))))

glimpse(ss)  
```

# Build some models

We will use the Relative Burn Ratio (RBR) from Parks et al (2014) as our response variable. Look at models at different scales

```{r build_models_continuous}
m1 <- lmer(RBR ~ het_ndvi_1_s * fm100_s + preFire_ndvi_s + topo_roughness_1_s + pdir_s + (1 | fire_id), data = ss)
m2 <- lmer(RBR ~ het_ndvi_2_s * fm100_s + preFire_ndvi_s + topo_roughness_2_s + pdir_s + (1 | fire_id), data = ss)
m3 <- lmer(RBR ~ het_ndvi_3_s * fm100_s + preFire_ndvi_s + topo_roughness_3_s + pdir_s + (1 | fire_id), data = ss)
m4 <- lmer(RBR ~ het_ndvi_4_s * fm100_s + preFire_ndvi_s + topo_roughness_4_s + pdir_s + (1 | fire_id), data = ss)

summary(m1)
summary(m2)
summary(m3)
summary(m4)

AIC(m1, m2, m3, m4)
```

Correlations amongst response variables?

```{r response_correlations}
pairs(samps[, c("RdNBR", "RdNBR2", "RdNDVI", "RdEVI", "RBR"), drop = TRUE])
```

Consider switching to a "high severity" / "not high severity" boolean response.

From the CBI calibration, we know that the 1-month window, bicubic interpolation of RBR is a "high severity" pixel when RBR > 0.2836425; Note that "high severity" is equivalent to "stand replacing".

Many (all?) researchers use the categorical response because remotely-sensed severity
metrics tend to have a non-linear relationship with on-the-ground severity

<!-- Consider replacing the below with output from explore_cbi.R script -->
Here are the other thresholds for the model using bicubic interpolation and a 1 month window:
0.037996297 equates to a CBI of 0
0.041191844 equates to a CBI of 0.1 -- threshold between "unchanged" and "low"
0.11191955 equates to a CBI of 1.25 -- threshold between "low" and "medium"
0.2836425 equates to a CBI of 2.25 -- threshold between "medium" and "high"

```{r high_v_not-high}
ss$stand_replacing <- ifelse(ss$RBR > 0.2836425, yes = 1, no = 0)
```


Our modeling effort then becomes a generalized linear model with a logit link, estimating how different covariate affect the *probability* of a high severity fire

```{r build_model_binomial}
glm1 <- glmer(stand_replacing ~ het_ndvi_1_s * fm100_s + preFire_ndvi_s + topo_roughness_1_s + pdir_s + (1 | fire_id), 
              data = ss, 
              family = "binomial",
              control = glmerControl(optimizer = "bobyqa"))

summary(glm1)

```


The theory that we'd **really** like to test is that heterogeneity matters under some fuel/weather conditions, but is overwhelmed by extreme conditions

1) If there's a ton of fuel (i.e., high greenness), how does that affect heterogeneity?
Here are some important interacters with heterogeneity.
Just a check here: neighborhood windows with very low and very high mean values of greenness should have low heterogeneity. Heterogeneity requires variation, and there can't be variation at the extreme values of mean neighborhood greeness.

This plot is beautifully concave down:

```{r focal_mean_v_focal_het, cache = TRUE}
ggplot(ss, aes(x = focal_mean_ndvi_1, y = het_ndvi_1)) +
  geom_point() + 
  geom_smooth(method = "loess")
```

We expect that low and high mean neighborhood values of greeness (e.g., NDVI) should result in low heterogeneity. Heterogeneity requires variation, so if all nearby pixels are low or high in NDVI, then no variation is possible.

**But**, we also find that high greeness pixels tend to be around more high greenness pixels. So we just don't get heterogeneity in places where the focal pixel is very green. You don't get a scenario where there is a dense patch of trees, and heterogeneous forest nearby.

This plot is fairly flat until a point, then it declines quickly.

```{r center_mean_v_focal_het, cache = TRUE}
ggplot(ss, aes(x = preFire_ndvi, y = het_ndvi_1)) +
  geom_point() +
  geom_smooth(method = "loess")
```

So that non-linearity poses a problem for answering the question that we really want to ask
Any signal of heterogeneity is lost at high levels of greenness
As an example, subset the data to only include preFire_ndvi values where heterogeneity is even (i.e., prior to the declining relationship between focal pixel greenness and heterogeneity)

```{r split_model}
glm2 <- glmer(stand_replacing ~  het_ndvi_1_s * fm100_s + preFire_ndvi_s + topo_roughness_1_s + pdir_s + (1 | fire_id), 
              data = ss[ss$preFire_ndvi < 0.5, ], 
              family = "binomial",
              control = glmerControl(optimizer = "bobyqa"))

summary(glm2)
```

All of a sudden, a huge impact of heterogeneity, as we expected. How best to account for this?

2) If there is high ERC or low fm100, how does that affect the impact of heterogeneity?

3) What is the relationship between different scales of heterogeneity?

Pretty highly correlated, and declining as scales diverge:

```{r het_correlations, cache = TRUE}
cor(ss[, c("het_ndvi_1", "het_ndvi_2", "het_ndvi_3", "het_ndvi_4"), drop = TRUE])
pairs(ss[, c("het_ndvi_1", "het_ndvi_2", "het_ndvi_3", "het_ndvi_4"), drop = TRUE])
```

4) What is the relationship between roughness and heterogeneity?

A negative correlation:

```{r rough_v_het, cache = TRUE}
cor(ss$topo_roughness_1, ss$het_ndvi_1)
ggplot(ss, aes(x = topo_roughness_1, y = het_ndvi_1)) +
  geom_point() +
  geom_smooth(method = "lm")
```

The linear regressions get the marginal effect of each variable at the *mean* of other variables:

```{r mean_of_predictors}
ss %>%
  summarize_at(vars(het_ndvi_1, fm100, preFire_ndvi, topo_roughness_1, pdir), mean)
```

And the means when subset to low NDVI at focal pixel:

```{r mean_at_low_ndvi}
ss %>%
  filter(preFire_ndvi < 0.5) %>%
  summarize_at(vars(het_ndvi_1, fm100, preFire_ndvi, topo_roughness_1, pdir), mean)
```


What is the relationship between neighborhood mean NDVI and focal pixel NDVI?

```{r center_v_focal_ndvi, cache - TRUE}
ggplot(ss, aes(y = focal_mean_ndvi_1, x = preFire_ndvi)) +
  geom_point() +
  geom_smooth()

ggplot(ss, aes(y = focal_mean_ndvi_2, x = preFire_ndvi)) +
  geom_point() +
  geom_smooth()

ggplot(ss, aes(y = focal_mean_ndvi_3, x = preFire_ndvi)) +
  geom_point() +
  geom_smooth()

ggplot(ss, aes(y = focal_mean_ndvi_4, x = preFire_ndvi)) +
  geom_point() +
  geom_smooth()
```

